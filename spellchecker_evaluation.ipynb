{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spellcheckers\n",
    "\n",
    "We evaluated five different Python spellchecking libraries, each with its own approach and characteristics:\n",
    "\n",
    "### TextBlob\n",
    "A simple NLP library that provides a straightforward API for common natural language processing tasks. Its spellchecking functionality is based on Peter Norvig's algorithm and uses NLTK internally. TextBlob considers both a word list approach and basic pattern matching, but primarily focuses on being an easy-to-use, general-purpose NLP tool rather than a specialized spellchecker.\n",
    "\n",
    "\n",
    "### PySpellChecker\n",
    "An implementation of Peter Norvig's spelling correction algorithm that uses word frequency lists to suggest corrections. It calculates edit distance between a misspelled word and potential corrections, suggesting the most probable correct spelling based on word frequency in its dictionary.\n",
    "\n",
    "### SymSpell\n",
    "A symbolic spelling correction algorithm that offers extremely fast spell checking through optimized edit distance calculations. It generates all possible terms within an edit distance threshold using a precomputed deletion dictionary, making it significantly faster than traditional approaches.\n",
    "\n",
    "### Spello\n",
    "A machine learning-based spell checker that can be trained on domain-specific data. It combines traditional spell checking techniques with modern ML approaches, allowing it to learn from context and adapt to specific use cases.\n",
    "\n",
    "### Autocorrect\n",
    "A simple, lightweight spell checker that focuses on common misspellings and typos. It uses a combination of word lists and simple rules to make corrections, primarily targeting common typing errors rather than complex spelling mistakes.\n",
    "\n",
    "Each spellchecker represents a different approach to the spell-checking problem, from simple word list comparisons to sophisticated machine learning methods, offering various trade-offs between speed, accuracy, and flexibility.\n",
    "\n",
    "Most models can be imported directly into python, however, to use spello, u need a pretrained model (or train own yourself xD) and place it in [pythonModels](/data/pythonModels).\n",
    "I used this [model](https://haptik-website-images.haptik.ai/spello_models/en.pkl.zip), unzip it and place it in [/data/pythonModels](/data/pythonModels)."
   ],
   "id": "fe86751fc51bc102"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "\n",
    "### Dataset information\n",
    "The dataset we used is the dataset of [Peter Novig](https://www.kaggle.com/datasets/bittlingmayer/spelling), which contains five different sets of english correctly spelled words as well as their incorrect spelling, among others the wikipedia and birkspell sets.\n",
    "\n",
    "Also, there are interesting ways to generate misspelled words from the correct ones described in this [article](https://www.ijcaonline.org/archives/volume176/number27/yunus-2020-ijca-920288.pdf), where it is suggested to swap letters, add new letters and use keyboard characters relative positions. \n",
    "We provided an approach in the [data_preparation.py](/src/data_preparation.py) file in the generate_synthetic_errors() method. \n",
    "However, in this evaluation we have focused on the current datasets as they offer already sufficient variability.\n",
    "\n",
    "Of course, you can use any of the mentioned files, for our evaluation, we used the wikipedia.txt set.\n",
    "\n",
    "### Dataset preprocessing\n",
    "\n",
    "Because a different number of potential misspelled forms are presented for each correct word in the dataset, we first need to preprocess the data to a csv file to create\n",
    "correct-error pairs for each word. This is done by calling the data_preparation.py script.\n",
    "\n",
    "As mentioned, you can choose the different datasets processed (also multiple at a time). We are currently using wikipedia.txt.\n",
    "The processed csv-file is stored in the [spelling_errors.csv](/data/processed/spelling_errors.csv).\n"
   ],
   "id": "dab5cef05c325f8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:34:21.012990Z",
     "start_time": "2024-11-01T14:34:20.312616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data_preparation import main\n",
    "\"\"\"\n",
    "Select ur data files here. Options:\n",
    "\n",
    "\"data/raw/aspell.txt\", \"data/raw/birkbeck.txt\", \"data/raw/spell-testset1.txt\", \"data/raw/spell-testset2.txt\", \"data/raw/wikipedia.txt\"\n",
    "\n",
    "\"\"\"\n",
    "src_path = [\"data/raw/wikipedia.txt\"]\n",
    "main(src_path)"
   ],
   "id": "83d290e29917cf16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data/raw/wikipedia.txt: 2455 errors\n",
      "Total spelling errors collected: 2455\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Metrics\n",
    "\n",
    "For our evaluation, we classify the classic four different cases:\n",
    "* **True positives (tp)**: invalid words, recognized by spelling checker as misspelled and corrected properly.\n",
    "* **False positives (fp)**: valid words, recognized by checker as misspelled and changed unnecessarily.\n",
    "* **True negatives (tn)**: valid words, recognized by checker as correctly spelled and left unchanged.\n",
    "* **False negatives (fn)**: invalid words, recognized by checker as correctly spelled or corrected incorrectly.\n",
    "\n",
    "We used the classic data mining metrics for classification, which are the following:\n",
    "\n",
    "### 1. Recall\n",
    "Recall describes the proportion of misspelled words that were correctly identified and fixed by the spellchecker compared to all misspelled words in the text. A high recall means the spellchecker catches most spelling errors.\n",
    "\n",
    "$\\text{recall} = \\frac{tp}{tp + fn}$\n",
    "\n",
    "Optimal value: 1.0 (100% of misspellings detected and corrected)\n",
    "\n",
    "### 2. Precision\n",
    "Precision measures how many of the spellchecker's corrections were actually necessary and correct. It tells us how trustworthy the spellchecker's suggestions are and whether it tends to make unnecessary corrections.\n",
    "\n",
    "$\\text{precision} = \\frac{tp}{tp + fp}$\n",
    "\n",
    "Optimal value: 1.0 (all corrections made were necessary and correct)\n",
    "\n",
    "### 3. Accuracy\n",
    "Accuracy represents the overall correctness of the spellchecker's decisions, including both its ability to correct misspelled words and preserve correct ones. It gives us a general measure of how reliable the spellchecker is across all cases.\n",
    "\n",
    "$\\text{accuracy} = \\frac{tp + tn}{tp + tn + fp + fn}$\n",
    "\n",
    "Optimal value: 1.0 (perfect decisions for both corrections and preservation)\n",
    "\n",
    "### 4. F1 Score\n",
    "The F1 score provides a balanced measure between precision and recall. It's particularly useful when we need a single metric to compare spellcheckers, as it penalizes extreme imbalances between precision and recall.\n",
    "\n",
    "$\\text{F1} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$\n",
    "\n",
    "Optimal value: 1.0 (perfect balance between precision and recall)\n",
    "\n",
    "Furthermore, we also evaluate the processing speed of each spellchecker, as real-world applications often require a balance between accuracy and performance.\n"
   ],
   "id": "bca4412b9e0d06ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "\n",
    "Our `SpellCheckerEvaluator` implements a small framework for testing different spellchecking libraries. The evaluation process works as follows:\n",
    "\n",
    "1. **Initialization**: The evaluator loads a CSV dataset containing pairs of correct words and their misspelled versions. It initializes our five different spellcheckers\n",
    "\n",
    "2. **Evaluation Process**: For each spellchecker, the evaluator:\n",
    "   - Tests error correction by checking if misspelled words are corrected to their proper form\n",
    "   - Samples a subset (default 10%) of correct words to verify they aren't incorrectly modified\n",
    "   - Records our four key outcomes in a confusion matrix\n",
    "\n",
    "3. **Metrics Calculation**: The evaluator computes the standard classification metrics we defined earlier:\n",
    "   - Precision: Accuracy of corrections made\n",
    "   - Recall: Proportion of errors caught\n",
    "   - Accuracy: Overall correctness\n",
    "   - F1 Score: Balanced metric between precision and recall\n",
    "   - Processing Time: Speed of corrections\n",
    "\n",
    "4. **Results**: The evaluation results are:\n",
    "   - Displayed in a formatted table\n",
    "   - Saved to a CSV file for further analysis\n",
    "   - Include relative speed comparisons normalized to the fastest checker\n",
    "\n",
    "The evaluator is designed to be extensible and can be easily modified to include additional spellcheckers or metrics.\n",
    "\n",
    "\n"
   ],
   "id": "fd34ab6a1cd591f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:40:55.366921Z",
     "start_time": "2024-11-01T14:34:37.808121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.spell_checker_setup import SpellCheckerEvaluator\n",
    "\n",
    "evaluator = SpellCheckerEvaluator('data/processed/spelling_errors.csv')\n",
    "evaluator.evaluate()\n",
    "evaluator.print_results()\n"
   ],
   "id": "b5d722dbb8e50889",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spello\\model.py:301: UserWarning: This model was saved on spell<1.3.0. As such due to a bug in previous versions, none of customisations made to the config at the time of training were saved along with the model. It is recommended to load the model, apply all required customizations to config and save it again. E.g.\n",
      "\n",
      "from spello.model import SpellCorrectionModel \n",
      "sp = SpellCorrectionModel(language='en')  \n",
      "sp.load('/home/ubuntu/model.pkl')\n",
      "sp.config.min_length_for_spellcorrection = 4 # default is 3\n",
      "sp.config.max_length_for_spellcorrection = 12 # default is 15\n",
      "sp.save(model_save_dir='/home/ubuntu/')\n",
      "\n",
      "After this the model will load without any warnings\n",
      "\n",
      "  warnings.warn(\"This model was saved on spell<1.3.0. As such due to a bug in previous versions, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating textblob...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing textblob: 100%|██████████| 2455/2455 [02:52<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results for textblob:\n",
      "True Corrections (correctly fixed errors): 1514\n",
      "False Corrections (incorrectly fixed errors): 941\n",
      "False Alarms (incorrectly changed valid words): 36\n",
      "True Negatives (correctly preserved valid words): 227\n",
      "Total actual errors in dataset: 2455\n",
      "Total corrections attempted: 1550\n",
      "Total valid words tested: 263\n",
      "\n",
      "Evaluating pyspellchecker...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pyspellchecker: 100%|██████████| 2455/2455 [02:31<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results for pyspellchecker:\n",
      "True Corrections (correctly fixed errors): 1804\n",
      "False Corrections (incorrectly fixed errors): 651\n",
      "False Alarms (incorrectly changed valid words): 11\n",
      "True Negatives (correctly preserved valid words): 231\n",
      "Total actual errors in dataset: 2455\n",
      "Total corrections attempted: 1815\n",
      "Total valid words tested: 242\n",
      "\n",
      "Evaluating symspell...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing symspell: 100%|██████████| 2455/2455 [00:00<00:00, 10487.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results for symspell:\n",
      "True Corrections (correctly fixed errors): 1803\n",
      "False Corrections (incorrectly fixed errors): 652\n",
      "False Alarms (incorrectly changed valid words): 16\n",
      "True Negatives (correctly preserved valid words): 234\n",
      "Total actual errors in dataset: 2455\n",
      "Total corrections attempted: 1819\n",
      "Total valid words tested: 250\n",
      "\n",
      "Evaluating spello...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spello: 100%|██████████| 2455/2455 [00:03<00:00, 662.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results for spello:\n",
      "True Corrections (correctly fixed errors): 1724\n",
      "False Corrections (incorrectly fixed errors): 731\n",
      "False Alarms (incorrectly changed valid words): 23\n",
      "True Negatives (correctly preserved valid words): 226\n",
      "Total actual errors in dataset: 2455\n",
      "Total corrections attempted: 1747\n",
      "Total valid words tested: 249\n",
      "\n",
      "Evaluating autocorrect...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing autocorrect: 100%|██████████| 2455/2455 [00:40<00:00, 60.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results for autocorrect:\n",
      "True Corrections (correctly fixed errors): 1723\n",
      "False Corrections (incorrectly fixed errors): 732\n",
      "False Alarms (incorrectly changed valid words): 18\n",
      "True Negatives (correctly preserved valid words): 238\n",
      "Total actual errors in dataset: 2455\n",
      "Total corrections attempted: 1741\n",
      "Total valid words tested: 256\n",
      "\n",
      "Final Results:\n",
      "--------------------------------------------------\n",
      "                    textblob  pyspellchecker   symspell     spello  autocorrect\n",
      "True Corrections   1514.0000       1804.0000  1803.0000  1724.0000    1723.0000\n",
      "False Corrections   941.0000        651.0000   652.0000   731.0000     732.0000\n",
      "False Alarms         36.0000         11.0000    16.0000    23.0000      18.0000\n",
      "True Negatives      227.0000        231.0000   234.0000   226.0000     238.0000\n",
      "Precision             0.9768          0.9939     0.9912     0.9868       0.9897\n",
      "Recall                0.6167          0.7348     0.7344     0.7022       0.7018\n",
      "Accuracy              0.6405          0.7545     0.7530     0.7212       0.7233\n",
      "F1 Score              0.7561          0.8450     0.8437     0.8206       0.8213\n",
      "Time (s)            172.4516        151.4001     0.2351     3.7040      40.9196\n",
      "\n",
      "Relative Speed (normalized to fastest):\n",
      "textblob: 733.56x\n",
      "pyspellchecker: 644.01x\n",
      "symspell: 1.00x\n",
      "spello: 15.76x\n",
      "autocorrect: 174.06x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualization and Results Analysis\n",
    "\n",
    "## Visualization Approach\n",
    "Our [visualizations.py](/src/visualizations.py) script provides an overview of the spellcheckers' performance through five distinct visualizations:\n",
    "\n",
    "1. **Spider/Radar Plot**: Shows the four key metrics (Precision, Recall, Accuracy, F1 Score) for each spellchecker, allowing quick comparison of overall performance patterns and identifying balanced versus specialized tools.\n",
    "\n",
    "2. **Stacked Percentage Bar Chart**: Displays the proportion of correct versus incorrect decisions, normalizing the results to percentages for fair comparison regardless of the number of words processed.\n",
    "\n",
    "3. **Processing Time Comparison**: Uses a logarithmic scale bar chart to compare execution times, clearly showing the substantial performance differences between implementations.\n",
    "\n",
    "4. **Detailed Error Analysis**: Breaks down the specific types of errors (True Corrections, False Corrections, False Alarms) made by each spellchecker, helping identify particular strengths and weaknesses.\n",
    "\n",
    "5. **Error Pattern Heatmap**: Visualizes the distribution of different error types through a color-coded matrix, making it easy to spot systematic issues in each spellchecker's approach.\n",
    "\n",
    "\n",
    "The visualizations can be found in the [results/graphs](/results/graphs) directory\n",
    "\n"
   ],
   "id": "33dc63f57d4ea82d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T14:53:26.832722Z",
     "start_time": "2024-11-01T14:53:23.879982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.visualizations import visualize_results\n",
    "\n",
    "visualize_results()"
   ],
   "id": "7f320819dd8692a3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results Analysis and Recommendations\n",
    "\n",
    "## Performance Analysis\n",
    "\n",
    "### Precision (Ability to make correct changes)\n",
    "All spellcheckers show remarkably high precision (>97%):\n",
    "- PySpellChecker leads with 99.39%\n",
    "- SymSpell follows closely at 99.12%\n",
    "- TextBlob, despite lower overall performance, still achieves 97.68%\n",
    "This indicates that when these tools make corrections, they are highly confident and accurate.\n",
    "\n",
    "### Recall (Ability to catch errors)\n",
    "The recall scores show more variation:\n",
    "- PySpellChecker leads at 73.48%\n",
    "- SymSpell very close at 73.44%\n",
    "- TextBlob significantly lower at 61.67%\n",
    "This suggests that while corrections are accurate, all spellcheckers miss a significant portion of errors.\n",
    "\n",
    "### Processing Speed\n",
    "Speed differences are dramatic:\n",
    "- SymSpell: 0.24 seconds (fastest)\n",
    "- Spello: 3.70 seconds (15x slower than SymSpell)\n",
    "- Autocorrect: 40.92 seconds\n",
    "- PySpellChecker: 151.40 seconds\n",
    "- TextBlob: 172.45 seconds (730x slower than SymSpell)\n",
    "\n",
    "### Error Analysis\n",
    "- False Alarms (incorrectly changing correct words):\n",
    "  - PySpellChecker: Only 11 cases\n",
    "  - SymSpell: 16 cases\n",
    "  - TextBlob: Highest at 36 cases\n",
    "\n",
    "- False Corrections:\n",
    "  - PySpellChecker/SymSpell: ~650 cases\n",
    "  - TextBlob: Highest at 941 cases\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "### Best Overall Choice: SymSpell\n",
    "- Nearly identical accuracy to the best performer (PySpellChecker)\n",
    "- Dramatically faster than all alternatives (0.24 seconds vs next best 3.70 seconds)\n",
    "- Excellent precision (99.12%) and recall (73.44%)\n",
    "- Perfect for production environments where both speed and accuracy matter\n",
    "\n",
    "### Best for Quality-Critical Applications: PySpellChecker\n",
    "- Highest precision (99.39%)\n",
    "- Best recall (73.48%)\n",
    "- Lowest false alarm rate (11 cases)\n",
    "- Best suited for applications where processing time isn't critical\n",
    "\n",
    "### Best Compromise: Spello\n",
    "- Good balance of performance (72.12% accuracy)\n",
    "- Reasonable processing speed (3.70 seconds)\n",
    "- Solid choice for medium-sized applications\n",
    "\n",
    "### Use Case Specific Recommendations:\n",
    "1. **High-Volume Processing**: SymSpell\n",
    "   - Orders of magnitude faster\n",
    "   - Minimal accuracy trade-off\n",
    "\n",
    "2. **Critical Document Processing**: PySpellChecker\n",
    "   - Highest accuracy\n",
    "   - Lowest risk of introducing errors\n",
    "   - Use when processing time isn't critical\n",
    "\n",
    "3. **Real-time Applications**: SymSpell or Spello\n",
    "   - Both offer good response times\n",
    "   - Good accuracy balance\n",
    "\n",
    "4. **Budget/Resource Constrained**: SymSpell\n",
    "   - Fastest processing\n",
    "   - Lowest computational resource requirements\n",
    "   - Excellent accuracy\n",
    "\n",
    "Not Recommended: TextBlob for spellchecking\n",
    "- Lowest performance across most metrics\n",
    "- Slowest processing time\n",
    "- Highest false alarm rate\n",
    "- Better suited for its primary purpose as a general NLP toolkit\n",
    "\n",
    "The data shows that modern spellcheckers are highly precise but still miss about 25-40% of errors. This suggests room for improvement, possibly through ensemble approaches or better context understanding.\n"
   ],
   "id": "303363000f8ce8ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
